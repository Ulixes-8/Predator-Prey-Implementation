{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df794f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "plot_performance_results.ipynb\n",
    "\n",
    "Reads JSON performance result files (from 'performance_results') for two experiment types:\n",
    "    - grid_scaling\n",
    "    - landscape_prop\n",
    "\n",
    "Generates two separate charts plotting the results for each experiment type.\n",
    "These include: baseline, refactoring_1, refactoring_2, and refactoring_3.\n",
    "The charts show the average time taken for each approach, with error bars indicating the standard deviation.\n",
    "The charts are displayed using Matplotlib.\n",
    "\"\"\"\n",
    "\n",
    "# ─── Cell #1: Imports and Global Constants ─────────────────────────────────────\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import statistics\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Using seaborn for enhanced aesthetics\n",
    "\n",
    "# Set a sleek, academic style with seaborn and update matplotlib settings\n",
    "sns.set_theme(style=\"ticks\", context=\"talk\", palette=\"deep\")\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 16,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'lines.linewidth': 2.5,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "})\n",
    "# Base path where the results are located\n",
    "BASE_PATH = \".\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3465469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell #2: Data Parsing Functions (With Debug Prints) ──────────────────────\n",
    "\n",
    "def parse_landscape_prop_results(folder_path: str, debug: bool = False) -> Dict[str, List[Tuple[float, float, float]]]:\n",
    "    \"\"\"\n",
    "    Parses JSON files matching '*_landscape_prop.json' in 'folder_path'.\n",
    "\n",
    "    Each file is treated as one approach (e.g. 'BASELINE', 'REFACTOR_1', etc.).\n",
    "    For each dimension (like '40x40') and land proportion (e.g. '0.10'),\n",
    "    we compute (mean_time, st_dev, land_prop).\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Directory containing the JSON files for the experiment.\n",
    "        debug (bool): If True, prints debugging information about times, mean, st.dev.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[float, float, float]]]:\n",
    "            Keys are approach names (e.g., 'BASELINE'),\n",
    "            Values are lists of (mean_time, std_time, land_prop).\n",
    "    \"\"\"\n",
    "    results_dict: Dict[str, List[Tuple[float, float, float]]] = {}\n",
    "\n",
    "    # Find files that match the pattern\n",
    "    json_files = glob.glob(os.path.join(folder_path, \"*_landscape_prop.json\"))\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] parse_landscape_prop_results -> Found {len(json_files)} files in {folder_path}\")\n",
    "\n",
    "    for file_path in json_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        approach_name = filename.split(\"_landscape_prop.json\")[0]\n",
    "        if approach_name not in results_dict:\n",
    "            results_dict[approach_name] = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for dimension_key, proportions_dict in data.get(\"results\", {}).items():\n",
    "            for prop_str, times in proportions_dict.items():\n",
    "                land_prop = float(prop_str)\n",
    "                mean_time = statistics.mean(times)\n",
    "                std_time = statistics.stdev(times) if len(times) > 1 else 0.0\n",
    "                if debug:\n",
    "                    print(f\"  [DEBUG] approach: {approach_name}, dimension: {dimension_key}, \"\n",
    "                          f\"prop: {prop_str}, times={times}\")\n",
    "                    print(f\"    mean_time={mean_time}, std_time={std_time}\")\n",
    "                results_dict[approach_name].append((mean_time, std_time, land_prop))\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def parse_grid_scaling_results(folder_path: str, debug: bool = False) -> Dict[str, List[Tuple[float, float, int]]]:\n",
    "    \"\"\"\n",
    "    Parses JSON files matching '*_grid_scaling.json' in 'folder_path'.\n",
    "\n",
    "    Each file is treated as one approach. For each dimension (like '160x160'),\n",
    "    we compute (mean_time, st_dev, grid_size).\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Directory containing the JSON files for the experiment.\n",
    "        debug (bool): If True, prints debugging information about times, mean, st.dev.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[float, float, int]]]:\n",
    "            Keys are approach names,\n",
    "            Values are lists of (mean_time, std_time, grid_size).\n",
    "    \"\"\"\n",
    "    results_dict: Dict[str, List[Tuple[float, float, int]]] = {}\n",
    "    json_files = glob.glob(os.path.join(folder_path, \"*_grid_scaling.json\"))\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] parse_grid_scaling_results -> Found {len(json_files)} files in {folder_path}\")\n",
    "\n",
    "    for file_path in json_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        approach_name = filename.split(\"_grid_scaling.json\")[0]\n",
    "        if approach_name not in results_dict:\n",
    "            results_dict[approach_name] = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for dimension_key, prop_dict in data.get(\"results\", {}).items():\n",
    "            grid_size = int(dimension_key.split(\"x\")[0])\n",
    "            for _, times in prop_dict.items():\n",
    "                mean_time = statistics.mean(times)\n",
    "                std_time  = statistics.stdev(times) if len(times) > 1 else 0.0\n",
    "                if debug:\n",
    "                    print(f\"  [DEBUG] approach: {approach_name}, dimension: {dimension_key}, times={times}\")\n",
    "                    print(f\"    mean_time={mean_time}, std_time={std_time}\")\n",
    "                results_dict[approach_name].append((mean_time, std_time, grid_size))\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell #3: Plotting Functions With Enhanced Aesthetics ─────────\n",
    "\n",
    "def plot_landscape_prop_results(\n",
    "    data: Dict[str, List[Tuple[float, float, float]]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the data for the 'landscape_prop' experiment on a single chart,\n",
    "    showing a shaded st.dev band between (mean - std) and (mean + std).\n",
    "\n",
    "    x-axis: landscape proportion\n",
    "    y-axis: average time\n",
    "\n",
    "    The legend is labeled with an aggregate st.dev measure (average)\n",
    "    for each approach.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    # Generate a color palette for the approaches\n",
    "    approaches = sorted(data.keys())\n",
    "    colors = sns.color_palette(\"deep\", n_colors=len(approaches))\n",
    "    \n",
    "    for idx, approach_name in enumerate(approaches):\n",
    "        tuples_list = data[approach_name]\n",
    "        # Sort by landscape proportion\n",
    "        sorted_list = sorted(tuples_list, key=lambda x: x[2])\n",
    "        mean_times  = [x[0] for x in sorted_list]\n",
    "        std_times   = [x[1] for x in sorted_list]\n",
    "        land_props  = [x[2] for x in sorted_list]\n",
    "        lower_bounds = [m - s for m, s in zip(mean_times, std_times)]\n",
    "        upper_bounds = [m + s for m, s in zip(mean_times, std_times)]\n",
    "        # Compute aggregate std for legend\n",
    "        avg_std = sum(std_times) / len(std_times) if std_times else 0.0\n",
    "        legend_label = f\"{approach_name} (avg st.dev={avg_std:.3f})\"\n",
    "        \n",
    "        # Plot main line with dedicated color and markersize\n",
    "        line_handle, = plt.plot(\n",
    "            land_props,\n",
    "            mean_times,\n",
    "            '-o',\n",
    "            markersize=8,\n",
    "            label=legend_label,\n",
    "            color=colors[idx]\n",
    "        )\n",
    "        # Fill between the error bounds\n",
    "        plt.fill_between(\n",
    "            land_props,\n",
    "            lower_bounds,\n",
    "            upper_bounds,\n",
    "            alpha=0.3,\n",
    "            color=colors[idx]\n",
    "        )\n",
    "\n",
    "    plt.title(\"Landscape Prop Experiment: Land Proportion vs. Time (± Std Dev)\")\n",
    "    plt.xlabel(\"Landscape Proportion\")\n",
    "    plt.ylabel(\"Average Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.minorticks_on()\n",
    "    sns.despine(trim=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_grid_scaling_results(\n",
    "    data: Dict[str, List[Tuple[float, float, int]]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the data for the 'grid_scaling' experiment on a single chart,\n",
    "    showing a shaded st.dev band between (mean - std) and (mean + std).\n",
    "\n",
    "    x-axis: grid dimension\n",
    "    y-axis: average time\n",
    "\n",
    "    The legend is labeled with an aggregate st.dev measure (average)\n",
    "    for each approach.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    approaches = sorted(data.keys())\n",
    "    colors = sns.color_palette(\"deep\", n_colors=len(approaches))\n",
    "    \n",
    "    for idx, approach_name in enumerate(approaches):\n",
    "        tuples_list = data[approach_name]\n",
    "        # Sort by grid size\n",
    "        sorted_list = sorted(tuples_list, key=lambda x: x[2])\n",
    "        mean_times  = [x[0] for x in sorted_list]\n",
    "        std_times   = [x[1] for x in sorted_list]\n",
    "        grid_sizes  = [x[2] for x in sorted_list]\n",
    "        lower_bounds = [m - s for m, s in zip(mean_times, std_times)]\n",
    "        upper_bounds = [m + s for m, s in zip(mean_times, std_times)]\n",
    "        \n",
    "        avg_std = sum(std_times) / len(std_times) if std_times else 0.0\n",
    "        legend_label = f\"{approach_name} (avg st.dev={avg_std:.3f})\"\n",
    "        \n",
    "        line_handle, = plt.plot(\n",
    "            grid_sizes,\n",
    "            mean_times,\n",
    "            '-o',\n",
    "            markersize=8,\n",
    "            label=legend_label,\n",
    "            color=colors[idx]\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            grid_sizes,\n",
    "            lower_bounds,\n",
    "            upper_bounds,\n",
    "            alpha=0.3,\n",
    "            color=colors[idx]\n",
    "        )\n",
    "\n",
    "    plt.title(\"Grid Scaling Experiment: Grid Dimension vs. Time (± Std Dev)\")\n",
    "    plt.xlabel(\"Grid Dimension\")\n",
    "    plt.ylabel(\"Average Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.minorticks_on()\n",
    "    sns.despine(trim=True)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell #4: Main Execution───────────────────────────────\n",
    "\n",
    "def main(debug: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Example usage showing how to parse and plot both experiment types.\n",
    "    Set 'debug=True' to see extra prints of times, means, st.dev, etc.\n",
    "    \"\"\"\n",
    "    BASE_PATH = \".\"\n",
    "    # Parse and plot landscape_prop results\n",
    "    lp_folder = os.path.join(BASE_PATH, \"landscape_prop\")\n",
    "    lp_data = parse_landscape_prop_results(lp_folder, debug=debug)\n",
    "    plot_landscape_prop_results(lp_data)\n",
    "    plt.show()\n",
    "\n",
    "    # Parse and plot grid_scaling results\n",
    "    gs_folder = os.path.join(BASE_PATH, \"grid_scaling\")\n",
    "    gs_data = parse_grid_scaling_results(gs_folder, debug=debug)\n",
    "    plot_grid_scaling_results(gs_data)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db723050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell #5: Extended Horizon Comparison for REFACTOR_2 vs REFACTOR_3 ─────────\n",
    "\n",
    "def plot_extended_horizon_comparison(debug: bool = False):\n",
    "    \"\"\"\n",
    "    Plots REFACTOR_2 vs REFACTOR_3 over extended grid sizes for Experiment_2.\n",
    "    Only loads and displays these two files.\n",
    "    \"\"\"\n",
    "    folder_path = os.path.join(BASE_PATH, \"grid_scaling\")\n",
    "    ref2_path = os.path.join(folder_path, \"REFACTOR_2_grid_scaling_Experiment_2.json\")\n",
    "    ref3_path = os.path.join(folder_path, \"REFACTOR_3_grid_scaling_Experiment_2.json\")\n",
    "\n",
    "    def load_and_extract(file_path: str) -> List[Tuple[float, float, int]]:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        result = []\n",
    "        for dim_key, prop_dict in data.get(\"results\", {}).items():\n",
    "            grid_size = int(dim_key.split(\"x\")[0])\n",
    "            for _, times in prop_dict.items():\n",
    "                mean_time = statistics.mean(times)\n",
    "                std_time = statistics.stdev(times) if len(times) > 1 else 0.0\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] {file_path} → {dim_key}: {times} → mean={mean_time}, std={std_time}\")\n",
    "                result.append((mean_time, std_time, grid_size))\n",
    "        return sorted(result, key=lambda x: x[2])  # sort by grid size\n",
    "\n",
    "    ref2_data = load_and_extract(ref2_path)\n",
    "    ref3_data = load_and_extract(ref3_path)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    for idx, (label, data) in enumerate([(\"REFACTOR_2\", ref2_data), (\"REFACTOR_3\", ref3_data)]):\n",
    "        means = [x[0] for x in data]\n",
    "        stds  = [x[1] for x in data]\n",
    "        sizes = [x[2] for x in data]\n",
    "        lower = [m - s for m, s in zip(means, stds)]\n",
    "        upper = [m + s for m, s in zip(means, stds)]\n",
    "        avg_std = sum(stds) / len(stds) if stds else 0.0\n",
    "        legend_label = f\"{label} (avg st.dev={avg_std:.3f})\"\n",
    "        plt.plot(sizes, means, '-o', markersize=8, label=legend_label, color=sns.color_palette()[idx])\n",
    "        plt.fill_between(sizes, lower, upper, alpha=0.3, color=sns.color_palette()[idx])\n",
    "\n",
    "    plt.title(\"Extended Horizon Comparison: REFACTOR_2 vs REFACTOR_3 (± Std Dev)\")\n",
    "    plt.xlabel(\"Grid Dimension\")\n",
    "    plt.ylabel(\"Average Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.minorticks_on()\n",
    "    sns.despine(trim=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_extended_horizon_comparison(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell #6: Extrapolated Performance with Hour Conversions and Differences (Second degree polynomial) ─────────\n",
    "\n",
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "def extrapolate_and_plot() -> None:\n",
    "    \"\"\"\n",
    "    Loads performance data from REFACTOR_2 and REFACTOR_3 JSON files,\n",
    "    fits a polynomial (degree 3) to the real data, and extrapolates performance\n",
    "    values for larger grid sizes. It then plots both the real and the extrapolated data,\n",
    "    and creates a summary table with the extrapolated results in seconds and hours,\n",
    "    including the computed differences between the two approaches.\n",
    "    \"\"\"\n",
    "    # Define the folder and file paths (using BASE_PATH from Cell #1)\n",
    "    folder_path = os.path.join(BASE_PATH, \"grid_scaling\")\n",
    "    ref2_path = os.path.join(folder_path, \"REFACTOR_2_grid_scaling_Experiment_2.json\")\n",
    "    ref3_path = os.path.join(folder_path, \"REFACTOR_3_grid_scaling_Experiment_2.json\")\n",
    "    \n",
    "    # Helper function to load and extract performance data.\n",
    "    # Returns a list of tuples: (mean_time, std_time, grid_size)\n",
    "    def load_and_extract(file_path: str) -> list[tuple[float, float, int]]:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        result = []\n",
    "        for dim_key, prop_dict in data.get(\"results\", {}).items():\n",
    "            # Extract grid size from keys like \"2560x2560\"\n",
    "            grid_size = int(dim_key.split(\"x\")[0])\n",
    "            for _, times in prop_dict.items():\n",
    "                mean_time = statistics.mean(times)\n",
    "                std_time = statistics.stdev(times) if len(times) > 1 else 0.0\n",
    "                result.append((mean_time, std_time, grid_size))\n",
    "        # Sort by grid size\n",
    "        result.sort(key=lambda tup: tup[2])\n",
    "        return result\n",
    "    \n",
    "    # Load performance data for both approaches.\n",
    "    ref2_data = load_and_extract(ref2_path)\n",
    "    ref3_data = load_and_extract(ref3_path)\n",
    "    \n",
    "    # Helper function to unpack grid sizes and mean times.\n",
    "    def unpack(data: list[tuple[float, float, int]]) -> tuple[np.ndarray, np.ndarray]:\n",
    "        sizes = [t[2] for t in data]\n",
    "        means = [t[0] for t in data]\n",
    "        return np.array(sizes), np.array(means)\n",
    "    \n",
    "    X2, y2 = unpack(ref2_data)\n",
    "    X3, y3 = unpack(ref3_data)\n",
    "    \n",
    "    # Fit a polynomial to the real data (degree 3, although the header indicates quadratic)\n",
    "    degree = 2\n",
    "    poly2 = np.poly1d(np.polyfit(X2, y2, degree))\n",
    "    poly3 = np.poly1d(np.polyfit(X3, y3, degree))\n",
    "    \n",
    "    # Define new (extrapolated) grid sizes.\n",
    "    extrap_grid_sizes = np.array([5120, 10240, 20480, 40960, 81920, 163840])\n",
    "    extrap_y2 = poly2(extrap_grid_sizes)\n",
    "    extrap_y3 = poly3(extrap_grid_sizes)\n",
    "    \n",
    "    # Plot the real data and the extrapolated curves.\n",
    "    plt.figure()\n",
    "    plt.plot(X2, y2, 'o-', label=\"REFACTOR_2 (Real)\", color='tab:blue')\n",
    "    plt.plot(X3, y3, 'o-', label=\"REFACTOR_3 (Real)\", color='tab:orange')\n",
    "    plt.plot(extrap_grid_sizes, extrap_y2, '--o', label=\"REFACTOR_2 (Extrapolated)\", color='tab:blue')\n",
    "    plt.plot(extrap_grid_sizes, extrap_y3, '--o', label=\"REFACTOR_3 (Extrapolated)\", color='tab:orange')\n",
    "    \n",
    "    plt.title(\"Extrapolated Grid Scaling Performance\")\n",
    "    plt.xlabel(\"Grid Size\")\n",
    "    plt.ylabel(\"Average Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.minorticks_on()\n",
    "    sns.despine(trim=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a DataFrame for the extrapolated results (in seconds).\n",
    "    table = pd.DataFrame({\n",
    "        \"Grid Size\": extrap_grid_sizes,\n",
    "        \"REFACTOR_2 (s)\": extrap_y2,\n",
    "        \"REFACTOR_3 (s)\": extrap_y3\n",
    "    })\n",
    "    \n",
    "    # Create columns for hours (seconds divided by 3600).\n",
    "    table[\"REFACTOR_2 (h)\"] = table[\"REFACTOR_2 (s)\"] / 3600\n",
    "    table[\"REFACTOR_3 (h)\"] = table[\"REFACTOR_3 (s)\"] / 3600\n",
    "    \n",
    "    # Calculate the differences (REFACTOR_2 - REFACTOR_3), in seconds and hours.\n",
    "    table[\"Diff (s)\"] = table[\"REFACTOR_2 (s)\"] - table[\"REFACTOR_3 (s)\"]\n",
    "    table[\"Diff (h)\"] = table[\"Diff (s)\"] / 3600\n",
    "    \n",
    "    # Display the table with all columns.\n",
    "    display(table)\n",
    "\n",
    "# Call the function to produce the plot and display the extrapolation table.\n",
    "extrapolate_and_plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
